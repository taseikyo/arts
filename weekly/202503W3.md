> @Author  : Lewis Tian (taseikyo@gmail.com)
>
> @Link    : github.com/taseikyo
>
> @Range   : 2025-03-16 - 2025-03-22

# Weekly #106

[readme](../README.md) | [previous](202503W2.md) | [next](202503W4.md)

![](../images/2025/03/xueliang-chen-UtTeNR8pnN4-unsplash.jpg "Weekly #106")

\**Photo by [Xueliang Chen](https://unsplash.com/@neko3000) on [Unsplash](https://unsplash.com/photos/a-woman-sitting-on-a-bench-next-to-a-tree-UtTeNR8pnN4)*

> åœ¨æ‹¿æªçš„æ•Œäººè¢«æ¶ˆç­ä»¥åï¼Œä¸æ‹¿æªçš„æ•Œäººä¾ç„¶å­˜åœ¨ï¼Œä»–ä»¬å¿…ç„¶åœ°è¦å’Œæˆ‘ä»¬ä½œæ‹šæ­»çš„æ–—äº‰ï¼Œæˆ‘ä»¬å†³ä¸å¯ä»¥è½»è§†è¿™äº›æ•Œäººã€‚å¦‚æœæˆ‘ä»¬ç°åœ¨ä¸æ˜¯è¿™æ ·åœ°æå‡ºé—®é¢˜å’Œè®¤è¯†é—®é¢˜ï¼Œæˆ‘ä»¬å°±è¦çŠ¯æå¤§çš„é”™è¯¯ã€‚ â€”â€” ã€Šåœ¨ä¸­å›½å…±äº§å…šç¬¬ä¸ƒå±Šä¸­å¤®å§”å‘˜ä¼šç¬¬äºŒæ¬¡å…¨ä½“ä¼šè®®ä¸Šçš„æŠ¥å‘Šã€‹ï¼ˆä¸€ä¹å››ä¹å¹´ä¸‰æœˆäº”æ—¥ï¼‰ï¼Œã€Šæ¯›æ³½ä¸œé€‰é›†ã€‹ç¬¬å››å·ç¬¬ä¸€å››äºŒå…«é¡µ

-[toc]

## algorithm [ğŸ”](#weekly-106)

## review [ğŸ”](#weekly-106)

### 1. [Apache Flink ä»å…¥é—¨åˆ°æ”¾å¼ƒâ€”â€”Flink ç®€ä»‹ï¼ˆä¸€ï¼‰](https://blog.csdn.net/LXWalaz1s1s/article/details/124538461)

#### 1. è®¡ç®—å¼•æ“çš„å‘å±•å†å²

éšç€å¤§æ•°æ®çš„å‘å±•ï¼Œå¤§æ•°æ®çš„å­˜å‚¨ã€è®¡ç®—ã€è¿ç”¨ç™¾èŠ±é½æ”¾ï¼›è€Œå¤§æ•°æ®çš„è®¡ç®—ä¸­æœ€é‡è¦çš„å°±æ˜¯è®¡ç®—å¼•æ“ï¼Œæ—¶è‡³ä»Šæ—¥ï¼Œå¾ˆå¤šäººå°†å¤§æ•°æ®å¼•æ“åˆ†ä¸ºå››ä»£ï¼Œåˆ†åˆ«æ˜¯ï¼š

1. ç¬¬ä¸€ä»£ï¼ŒHadoop æ‰¿è½½çš„ MapReduceï¼Œå°†è®¡ç®—åˆ†ä¸º Map å’Œ Reduce ä¸¤ä¸ªé˜¶æ®µï¼ŒåŒæ—¶é‡‡ç”¨ Hadoop é›†ç¾¤çš„åˆ†å¸ƒå¼è®¡ç®—åŸç†æ¥å®ç°æ•°æ®çš„è®¡ç®—ï¼Œä½†æ˜¯ MapReduce å­˜åœ¨å¾ˆæ˜æ˜¾çš„ç¼ºç‚¹
	1. é’ˆå¯¹å¤šä¸ªè¿­ä»£è®¡ç®—åªèƒ½ç”¨å¤šä¸ª Job çš„å¤šæ¬¡ MapReduce ä¸²è”å®Œæˆ
	2. å¤§é‡çš„ä¸­é—´ç»“æœè¦æº¢å†™åˆ°ç£ç›˜ï¼Œå› æ­¤å­˜åœ¨å¤§é‡çš„ç£ç›˜äº¤äº’ï¼Œæ•ˆç‡ååˆ†ä½ä¸‹ï¼›
2. ç¬¬äºŒä»£ï¼Œå¸¦æœ‰ DAGï¼ˆDirected Acyclic Graph æœ‰å‘æ— ç¯å›¾ï¼‰æ¡†æ¶çš„è®¡ç®—å¼•æ“ï¼Œå¦‚ Tez ä»¥åŠè°ƒåº¦çš„ Oozieï¼Œåœ¨ç¬¬ä¸€ä»£çš„åŸºç¡€ä¸Šå¢åŠ äº† DAGï¼Œä½†æ˜¯è¿ç®—æ•ˆç‡è¿˜æ˜¯è¾¾ä¸åˆ°è®¸å¤šéœ€æ±‚çš„è¦æ±‚ï¼›
3. ç¬¬ä¸‰ä»£ï¼Œä»¥ Spark ä¸ºä»£è¡¨çš„å†…å­˜è®¡ç®—å¼•æ“ï¼Œèµ¢å¾—äº†å†…å­˜è®¡ç®—çš„é£é€Ÿå‘å±•ï¼Œç¬¬ä¸‰ä»£è®¡ç®—å¼•æ“çš„ç‰¹ç‚¹æ˜¯ä¸»è¦ä¸ä»… DAGï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰ï¼Œä¹Ÿä»¥å†…å­˜ä¸ºèµŒæ³¨ï¼Œå¼ºè°ƒè®¡ç®—çš„å®æ—¶æ€§å‹ï¼Œæ˜¯ç›®å‰æ‰¹å¤„ç†çš„ä½¼ä½¼è€…ï¼Œç»™ç”¨æˆ·ååˆ†å‹å¥½çš„ä½“éªŒï¼Œä¸€åº¦è¢«äººè®¤ä¸ºè¦åœ¨è®¡ç®—å¼•æ“ä¸Šä¸€ç»Ÿå¤©ä¸‹çš„ï¼›
4. éšç€å®æ—¶è®¡ç®—éœ€æ±‚çš„è¿«åˆ‡æ€§ï¼Œå„ç§è¿­ä»£è®¡ç®—çš„æ€§èƒ½ä»¥åŠå¯¹æµå¼è®¡ç®—å’Œ SQL çš„æ”¯æŒï¼Œä»¥ Spark Streming ä¸ºä¾‹ä¹Ÿæ”¯æŒæµå¼è®¡ç®—ï¼Œè€Œä¸”èƒ½è§£å†³ 99% çš„æµå¼è®¡ç®—è¦æ±‚ï¼Œä½†æ˜¯ Spark Streaming è®¾è®¡ç†å¿µé‡Œé¢è®¤ä¸ºæµæ˜¯æ‰¹çš„æé™ï¼Œå³å¾®æ‰¹ï¼ˆmicro-batchï¼‰å°±æ˜¯æµå¼ï¼Œæ‰€ä»¥æœ‰ä¸ªè‡´å‘½çš„ç¼ºç‚¹å°±æ˜¯æ”’æ‰¹ï¼›å› ä¸ºè¿™ä¸ªç¼ºç‚¹çš„å­˜åœ¨ï¼Œå‰©ä¸‹çš„ 1% çš„æµå¼è¿ç®—å¹¶ä¸å¤ªé€‚åˆ Sparkï¼Œè€Œ Flink å°±å¾ˆå¥½çš„è§„é¿äº†è¿™ä¸ªç¼ºç‚¹ï¼Œè®¤ä¸ºæ‰¹æ˜¯æµçš„ç‰¹ä¾‹ï¼ŒæŠŠæ•°æ®è®¡ç®—å½’ä¸ºæœ‰ç•Œå’Œæ— ç•Œçš„ï¼Œæœ‰ç•Œçš„æ•°æ®å°±æ˜¯æ‰¹å¤„ç†ï¼Œæ— ç•Œçš„æ•°æ®å°±æ˜¯æµå¼ï¼Œè€Œä¸”ä»¥æµæ‰¹ä¸€ä½“ä¸ºç»ˆæè®¡ç®—ç›®æ ‡ï¼ŒFlink å°±è¢«å½’åœ¨ç¬¬å››ç±»å†…ï¼Œä»è¿™é‡Œå¼€å§‹æ—¶å°±æ­£å¼æ­å¼€ Flink çš„é¢çº±ï¼

#### 2. ä»€ä¹ˆæ˜¯ Flink

1ã€æ¦‚å¿µ

Apache Flink æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼å¤§æ•°æ®è®¡ç®—å¼•æ“ï¼Œå¯ä»¥å¯¹æœ‰ç•Œçš„æ•°æ®å’Œæ— ç•Œçš„æ•°æ®è¿›è¡Œæœ‰çŠ¶æ€çš„è®¡ç®—ï¼Œå¯éƒ¨ç½²åœ¨å„ç§é›†ç¾¤ç¯å¢ƒä¸­ï¼Œå¯¹å„ç§å¤§å°æ•°æ®è§„æ¨¡è¿›è¡Œå¿«é€Ÿè®¡ç®—ã€‚

Flink æ˜¯ä¸€ä¸ªæµå¼å¤§æ•°æ®å¤„ç†å¼•æ“ã€‚è€Œå†…å­˜æ‰§è¡Œé€Ÿåº¦å’Œä»»æ„è§„æ¨¡ï¼Œçªå‡ºäº† Flink çš„ä¸¤ä¸ªç‰¹ç‚¹ï¼šé€Ÿåº¦å¿«ã€å¯æ‰©å±•æ€§å¼ºã€‚

æ¡†æ¶å›¾ï¼š

![](../images/2025/03/36b7c6d765bc13154dcd69aae038ccee.png "Flink è®¡ç®—æ¶æ„å›¾")

2ã€ä»€ä¹ˆæ˜¯æœ‰ç•Œçš„æ•°æ®æµå’Œæ— ç•Œæ•°æ®æµï¼Ÿä»€ä¹ˆæ˜¯çŠ¶æ€ï¼Ÿ

åœ¨ Flink çš„è®¾è®¡ç†å¿µä¸­ï¼Œå°†æ•°æ®åˆ†ä¸ºæœ‰ç•Œæ•°æ®å’Œæ— ç•Œæ•°æ®ï¼Œå¦‚å›¾ 2.2ï¼›

- æœ‰ç•Œæ•°æ®(Bounded data)ï¼šå®šä¹‰äº†æ•°æ®çš„å¼€å§‹å’Œç»“æŸï¼Œä¹Ÿå°±æ˜¯æ‰¹å¤„ç†çš„æœ¬è´¨ï¼›
- æ— ç•Œæ•°æ®(Unbounded data)ï¼š æ•°æ®å®šä¹‰äº†å¼€å§‹ï¼Œä½†æ˜¯æ²¡æœ‰ç»“æŸï¼Œå› æ­¤éœ€è¦è¿ç»­ä¸æ–­çš„å¤„ç†è®¡ç®—ï¼Œå¦‚åŸºäºäº‹ä»¶çš„æœ‰åºé©±åŠ¨ã€‚

![](../images/2025/03/738830a5694cbacbaf104f0e387b66c0.png "æœ‰ç•Œæ•°æ®å’Œæ— ç•Œæ•°æ®çš„å¤„ç†")

- Flinkçš„çŠ¶æ€ï¼šFlink å†…ç½®çš„å¾ˆå¤šç®—å­ï¼ŒåŒ…æ‹¬æº sourceï¼Œæ•°æ®å­˜å‚¨ sink éƒ½æ˜¯æœ‰çŠ¶æ€çš„ã€‚åœ¨ Flink ä¸­ï¼ŒçŠ¶æ€å§‹ç»ˆä¸ç‰¹å®šç®—å­ç›¸å…³è”ã€‚Flink ä¼šä»¥checkpointçš„å½¢å¼å¯¹å„ä¸ªä»»åŠ¡çš„ çŠ¶æ€è¿›è¡Œå¿«ç…§ï¼Œç”¨äºä¿è¯æ•…éšœæ¢å¤æ—¶çš„çŠ¶æ€ä¸€è‡´æ€§ã€‚Flink é€šè¿‡çŠ¶æ€åç«¯æ¥ç®¡ç†çŠ¶æ€ å’Œ checkpoint çš„å­˜å‚¨ï¼ŒçŠ¶æ€åç«¯ä¹Ÿå¯ä»¥æœ‰ä¸åŒçš„é…ç½®é€‰æ‹©ï¼Œä¸ºä»€ä¹ˆç®—å­éœ€è¦çŠ¶æ€?

- å®ç°ç®—å­çš„é€»è¾‘ï¼ˆä½œä¸ºä¸€ç§ä¸­é—´çŠ¶æ€ï¼‰;
- é”™è¯¯æ¢å¤ï¼Œå¾€å¾€è®¡ç®—å¹¶ä¸èƒ½ä¸€æ­¥åˆ°ä½ï¼Œå¦‚æœæ²¡æœ‰è®°å½•çŠ¶æ€ï¼Œä¸€æ—¦ä¸­å•æœ‰ç®—å­å‡ºé”™ï¼Œä»£è¡¨æ•´ä¸ªè®¡ç®—è¦ä»å¤´ç®—èµ·ã€‚

3ã€Flink çš„ç‰¹ç‚¹

Flink åŒºåˆ«ä¸ä¼ ç»Ÿæ•°æ®å¤„ç†æ¡†æ¶çš„ç‰¹æ€§å¦‚ä¸‹ï¼š

1. æ”¯æŒjava(ä¸»)å’Œscala api(çœŸé¦™)ï¼Œæ–°ç‰ˆæœ¬æ”¯æŒpython api;
2. æµ (dataStream) æ‰¹(dataSet)ä¸€ä½“åŒ–ï¼Œæ”¯æŒäº‹ä»¶å¤„ç†å’Œæ— åºå¤„ç†é€šè¿‡ DataStreamAPIï¼ŒåŸºäº DataFlow æ•°æ®æµæ¨¡å‹ï¼Œåœ¨ä¸åŒçš„æ—¶é—´è¯­ä¹‰ (äº‹ä»¶æ—¶é—´ï¼Œæ‘„å–æ—¶é—´ã€å¤„ç†æ—¶é—´) ä¸‹æ”¯æŒçµæ´»çš„çª—å£(æ—¶é—´ï¼Œæ»‘åŠ¨ã€ç¿»æ»šï¼Œä¼šè¯ï¼Œè‡ªå®šä¹‰è§¦å‘å™¨;
3. æ”¯æŒæœ‰çŠ¶æ€è®¡ç®—çš„ Exactly-once(ä»…å¤„ç†ä¸€æ¬¡) å®¹é”™ä¿è¯ï¼Œæ”¯æŒåŸºå¹²è½»é‡çº§åˆ†å¸ƒå¼å¿«ç…§ checkpoint æœºåˆ¶å®ç°çš„å®¹é”™ï¼Œæ”¯æŒ savepoints æœºåˆ¶ï¼Œä¸€èˆ¬æ‰‹åŠ¨è§¦å‘ï¼Œåœ¨å‡çº§åº”ç”¨æˆ–è€…å¤„ç†å†å²æ•°æ®æ˜¯èƒ½å¤Ÿåšåˆ°æ— çŠ¶æ€ä¸¢å¤±å’Œæœ€å°åœæœºæ—¶é—´ï¼›
4. å…¼å®¹ hadoop çš„ mapreduceï¼Œé›†æˆ YARNã€HDFSã€Hbase å’Œå…¶å®ƒ hadoop ç”Ÿæ€ç³»ç»Ÿçš„ç»„ä»¶ï¼Œæ”¯æŒå¤§è§„æ¨¡çš„é›†ç¾¤æ¨¡å¼ï¼Œæ”¯æŒ yarnã€mesosã€‚å¯è¿è¡Œåœ¨æˆåƒä¸Šä¸‡çš„èŠ‚ç‚¹ä¸Šï¼Œå¯ä»¥è¿æ¥åˆ°æœ€å¸¸ç”¨çš„å­˜å‚¨ç³»ç»Ÿï¼Œå¦‚ Apache Kafkaã€ Apache Cassandraã€Elasticsearchã€JDBCã€ Kinesis å’Œï¼ˆåˆ†å¸ƒå¼ï¼‰æ–‡ä»¶ç³»ç»Ÿï¼Œå¦‚ HDFS å’Œ S3ã€‚
5. åœ¨ dataSet(æ‰¹å¤„ç†)API ä¸­å†…ç½®æ”¯æŒè¿­ä»£ç¨‹åº
6. å›¾å¤„ç† (æ‰¹) æœºå™¨å­¦ä¹  (æ‰¹) å¤æ‚äº‹ä»¶å¤„ç†(æµ)
7. è‡ªåŠ¨åå‹æœºåˆ¶åŠ é«˜å¯ç”¨ã€‚æœ¬èº«é«˜å¯ç”¨çš„è®¾ç½®ï¼ŒåŠ ä¸Šä¸ K8sï¼ŒYARN å’Œ Mesos çš„ç´§å¯†é›†æˆï¼Œå†åŠ ä¸Šä»æ•…éšœä¸­å¿«é€Ÿæ¢å¤å’ŒåŠ¨æ€æ‰©å±•ä»»åŠ¡çš„èƒ½åŠ›ï¼ŒFlink èƒ½åšåˆ°ä»¥æå°‘çš„åœæœºæ—¶é—´ 7x24 å…¨å¤©å€™è¿è¡Œï¼Œèƒ½å¤Ÿæ›´æ–°åº”ç”¨ç¨‹åºä»£ç å¹¶å°†ä½œä¸šï¼ˆjobsï¼‰è¿ç§»åˆ°ä¸åŒçš„ Flink é›†ç¾¤ï¼Œè€Œä¸ä¼šä¸¢å¤±åº”ç”¨ç¨‹åºçš„çŠ¶æ€ã€‚
8. é«˜æ•ˆçš„è‡ªå®šä¹‰å†…å­˜ç®¡ç†ï¼Œç»“æœçš„å‡†ç¡®æ€§ï¼Œ Flink æä¾›äº†äº‹ä»¶æ—¶é—´ï¼ˆevent-timeï¼‰å’Œå¤„ç†æ—¶é—´ï¼ˆprocessing-timeï¼‰
9. è¯­ä¹‰ã€‚å¯¹äºä¹±åºäº‹ä»¶æµï¼Œäº‹ä»¶æ—¶é—´è¯­ä¹‰ä»ç„¶èƒ½æä¾›ä¸€è‡´ä¸”å‡†ç¡®çš„ç»“æœã€‚
10. å¥å£®çš„åˆ‡æ¢èƒ½åŠ›åœ¨ in-memory å’Œ out-of-core ä¸­
11. é«˜ååå’Œä½å»¶è¿Ÿã€‚æ¯ç§’å¤„ç†æ•°ç™¾ä¸‡ä¸ªäº‹ä»¶ï¼Œæ¯«ç§’çº§å»¶è¿Ÿã€‚

4ã€Flink çš„åº”ç”¨

- æ‰¹å¤„ç†å’Œæµå¤„ç†
- æµæ•°æ®æ›´çœŸå®åœ°ååº”äº†æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼
- ä½å»¶æ—¶ã€é«˜ååã€ç»“æœå‡†ç¡®å’Œè‰¯å¥½çš„å®¹é”™æ€§
- æµæ‰¹ä¸€ä½“çš„ç»ˆæç›®æ ‡

![](../images/2025/03/5198c99dae90ab1931eae574ed5b7302.png "Flink æœ€ä½³çš„è¿ç”¨åœºæ™¯")

5ã€æµæ‰¹æ¶æ„çš„æ¼”å˜

1. ä¼ ç»Ÿå…³ç³»å‹æ•°æ®çš„ç³»ç»Ÿæ¶æ„ï¼Œå¦‚ MySQLã€SQL Server ä¸ºåå°æ•°æ®åº“çš„ OLTP ç³»ç»Ÿ

![](../images/2025/03/7dc8d6b868a4637d5595f8d24b29a813.png "äº‹åŠ¡å¤„ç†")

2. æœ‰çŠ¶æ€çš„æµå¤„ç†ï¼Œå› ä¸ºä¼ ç»Ÿçš„ OLTP ä¸å¤ªå¥½æ»¡è¶³ OLAP çš„æ•°æ®åˆ†æè€Œè¯ç”Ÿï¼Œå³å°†åº”ç”¨é€»è¾‘å’Œæœ¬åœ°çŠ¶æ€å­˜åœ¨å†…å­˜ï¼ŒåŒæ—¶å®šæœŸå­˜ç›˜æŒä¹…åŒ–ï¼Œä¿è¯æ•°æ®çš„ä¸è¢«ä¸¢å¤±ï¼Œæ­¤ç§æ¡†æ¶ä»¥ storm ä¸ºä»£è¡¨ï¼Œä½†æ˜¯ä¹Ÿå­˜åœ¨å¿…ç„¶ç¼ºé™·ï¼Œé‚£å°±æ˜¯æ•°æ®åœ¨åˆ†å¸ƒå¼çš„æœºå™¨ä¸‹ï¼Œå› ä¸ºç½‘ç»œç­‰ä¸ç¨³å®šå› ç´ ï¼Œæ— æ³•ä¿è¯æœ‰åºå’Œç²¾å‡†çš„ä¸€æ¬¡æ€§æ¶ˆè´¹ã€‚

![](../images/2025/03/a3c215143471b9c4590e7f4a557c2658.png "æœ‰çŠ¶æ€çš„æµå¤„ç†")

3. lambda æ¶æ„ï¼Œå³ç”¨æ¯ä¸€æ®µæ—¶é—´çš„æ‰¹å¤„ç†æ•°æ®åˆ·æ–°æœ€æ–°çš„æ•°æ®ï¼Œè€Œå½“æ—¶æœ€æ–°çš„æ•°æ®ç”¨æµå¤„ç†æ¥åšå¢é‡ï¼Œå¯ä»¥ç†è§£ä¸ºæ‰¹å¤„ç†åšä¸€æ¬¡è¦†ç›–ï¼Œæµå¤„ç†åšå®æ—¶å¢é‡ï¼Œå› ä¸ºæœ‰æ‰¹å¤„ç†çš„ä¿è¯ï¼Œæ•°æ®æœ€ç»ˆä¸€è‡´æ€§å¾—åˆ°ä¿è¯ï¼Œç¼ºç‚¹æ˜¯ç»´æŠ¤ä¸¤å¥—æ¶æ„ï¼Œå·¥ç¨‹é‡æ¯”è¾ƒå¤§ï¼›

![](../images/2025/03/aa9104a1ceb848365795b5391b2d8179.png "lambda æ¶æ„")

4. å®æ—¶æ•°ä»“æ¡†

1ï¼‰äº‹ä»¶é©±åŠ¨å‹å®æ—¶æ•°ä»“ï¼Œå‰ç«¯è¿ç”¨çš„äº‹ä»¶è§¦å‘ï¼ˆå¦‚ç‚¹å‡»æŒ‰é’®ã€æ‰«ç ç­‰ï¼‰å°†å…³é”®æ€§çš„æ•°æ®å˜åŒ–å†™å…¥æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆkafkaï¼ŒRabbitMQ ç­‰ï¼‰ï¼Œç„¶ååˆ©ç”¨ Flink æ¶ˆè´¹æ¶ˆæ¯é˜Ÿåˆ—çš„æ•°æ®è¿›è¡Œå¤„ç†ï¼Œå¤„ç†åçš„æ•°æ®å¯ä»¥æŒä¹…åŒ–å­˜å‚¨åˆ°å„å¤§å­˜å‚¨ç»„ä»¶å†…ï¼ˆhiveï¼Œhbaseï¼Œhdfs ç­‰ï¼‰ï¼Œä¹Ÿå¯ä»¥é‡æ–°å†™å›åˆ°æ¶ˆæ¯é˜Ÿåˆ—å†…ä¾›ä¸‹ä¸€ä¸ªè¿ç”¨ä½¿ç”¨ï¼›

![](../images/2025/03/012a22d6cfdeadca4524b6029ec2db3b.png "äº‹ä»¶é©±åŠ¨å‹å®æ—¶æ•°ä»“è¿ç”¨")

2ï¼‰ æ•°æ®åˆ†æå®æ—¶æ•°ä»“å‹ï¼Œä¸»è¦å°±æ˜¯é€šè¿‡æ ¹æ® OLTP ç³»ç»Ÿåç«¯æ•°æ®åº“çš„ change logï¼Œæ¥å®æ—¶å®šæœŸæ›´æ–°è‡³æ•°æ®æ•°ä»“çš„å­˜å‚¨åª’ä»‹ï¼ˆHDFSã€Hbaseã€ElasticSearchã€KuDuã€ClickHouseï¼‰ç­‰å†…ï¼Œå†å¤–æ¥å¯è§†åŒ–æŠ¥ï¼ˆapache supersetï¼‰è¡¨å®æ—¶å‘ˆç°æ•°æ®ï¼›

![](../images/2025/03/ddda1c5daab4b9cd073ceb183af763f1.png "æ•°æ®åˆ†æå®æ—¶æ•°ä»“å‹")

5ã€Flink çš„åˆ†å±‚ API

- è¶Šé¡¶å±‚è¶ŠæŠ½è±¡ï¼Œè¡¨è¾¾å«ä¹‰è¶Šç®€æ˜ï¼Œä½¿ç”¨è¶Šæ–¹ä¾¿
- è¶Šåº•å±‚è¶Šå…·ä½“ï¼Œè¡¨è¾¾èƒ½åŠ›è¶Šä¸°å¯Œï¼Œä½¿ç”¨è¶Šçµæ´»
- Flink ç‰ˆæœ¬æ›´æ–°è¿­ä»£æœ€ä¸»è¦åŸå› ä¹‹ä¸€ï¼šä¸°å¯Œä¸Šå±‚ API çš„å†…å®¹ï¼Œè®© Flink è¶Šæ¥è¶Šå®¹æ˜“çš„è¢«ä½¿ç”¨ï¼›

![](../images/2025/03/2af6e6f3307b3a3b3318140ed42ef1a4.png "Flink çš„åˆ†å±‚ API")

6ã€Flink VS Spark

![](../images/2025/03/2c4b366a4f084a3b9b5ccc2581987f69.png "Flink å¯¹æ¯” Spark")

- Spark è®¤ä¸ºæµæ˜¯æ‰¹çš„ç‰¹ä¾‹ï¼Œé‡‡ç”¨å¾®æ‰¹çš„æ¦‚å¿µï¼Œè¾“å…¥æ•°æ®æµè¿›æ¥å Spark Stream å°†æ•°æ®åˆ‡å‰²æˆä¸€ä¸ªä¸ªå¾®æ‰¹ï¼ˆMicro-batchï¼‰å¤„ç†ï¼›
- Flink å°†æ•°æ®åˆ†ä¸ºæœ‰ç•Œæ•°æ®å’Œæ— ç•Œæ•°æ®ï¼Œæœ‰ç•Œçš„æ•°æ®å°±æ˜¯æ‰¹å¤„ç†ï¼Œæ— ç•Œçš„æ•°æ®å°±æ˜¯æµè®¡ç®—ï¼›

- Spark é‡‡ç”¨ RDD æ¨¡å‹ï¼ŒSpark Streaming çš„ DStream å®é™…ä¸Šä¹Ÿå°±æ˜¯ä¸€ç»„å°æ‰¹æ•°æ® RDD çš„é›†åˆ
- Flink åŸºæœ¬æ•°æ®æ¨¡å‹æ˜¯æ•°æ®æµï¼Œä»¥åŠäº‹ä»¶ï¼ˆEventï¼‰åºåˆ—ï¼›

- Spark æ˜¯æ‰¹è®¡ç®—ï¼Œå°† DAG åˆ’åˆ†ä¸ºä¸åŒçš„ stageï¼Œä¸€ä¸ªå®Œæˆåæ‰å¯ä»¥è®¡ç®—ä¸‹ä¸€ä¸ªï¼›
- Flink æ˜¯æ ‡å‡†çš„æµæ‰§è¡Œæ¨¡å¼ï¼Œä¸€ä¸ªäº‹ä»¶åœ¨ä¸€ä¸ªèŠ‚ç‚¹å¤„ç†å®Œåå¯ä»¥ç›´æ¥å‘å¾€ä¸‹ä¸€ä¸ªèŠ‚ç‚¹è¿›è¡Œå¤„ç†ã€‚

![](../images/2025/03/1c1904030de1248a768ba5a1f0da9604.png "Flink å¯¹æ¯” Spark çš„è¿è¡Œæ—¶æ¡†æ¶å¯¹æ¯”")

Spark å’Œ Flink å¯ä»¥è¯´ç›®å‰æ˜¯å„æ“…èƒœåœºï¼Œæ‰¹å¤„ç†é¢†åŸŸ Spark ç§°ç‹ï¼Œè€Œåœ¨æµå¤„ç†æ–¹é¢ Flink å½“ä»ä¸è®©ã€‚å…·ä½“åˆ°é¡¹ç›®åº”ç”¨ä¸­ï¼Œä¸ä»…è¦çœ‹æ˜¯æµå¤„ç†è¿˜æ˜¯æ‰¹å¤„ç†ï¼Œè¿˜éœ€è¦åœ¨å»¶è¿Ÿã€ååé‡ã€å¯é æ€§ï¼Œä»¥åŠå¼€å‘å®¹æ˜“åº¦ã€å…¬å¸ IT èƒ½åŠ›ç­‰å¤šä¸ªæ–¹é¢è¿›è¡Œæƒè¡¡ã€‚

é‚£å¦‚æœç°åœ¨è¦å­¦ä¹ ä¸€é—¨æ¡†æ¶çš„è¯ï¼Œä¼˜å…ˆé€‰ Spark è¿˜æ˜¯ Flink å‘¢ï¼Ÿå…¶å®æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œä¸åŒçš„æ¡†æ¶å„æœ‰åˆ©å¼Šï¼ŒåŒæ—¶å®ƒä»¬ä¹Ÿåœ¨äº’ç›¸å€Ÿé‰´ã€å–é•¿è¡¥çŸ­ã€ä¸æ–­å‘å±•ï¼Œè‡³äºæœªæ¥æ˜¯ Spark è¿˜æ˜¯ Flinkã€ç”šè‡³æ˜¯å…¶ä»–æ–°å´›èµ·çš„å¤„ç†å¼•æ“ä¸€ç»Ÿæ±Ÿæ¹–ï¼Œéƒ½æ˜¯æœ‰å¯èƒ½çš„ï¼Œå’±ä»¬å°±ä¸”çœ‹ä»Šæ—¥ä¹‹åŸŸä¸­ï¼Œå°½æ˜¯è°å®¶ä¹‹å¤©ä¸‹ï¼Ÿ

### 2. [Apache Flink ä»å…¥é—¨åˆ°æ”¾å¼ƒâ€”â€”å¿«é€Ÿä¸Šæ‰‹ï¼ˆJava ç‰ˆï¼‰ï¼ˆäºŒï¼‰](https://blog.csdn.net/LXWalaz1s1s/article/details/124561252)

#### 1ã€ç¯å¢ƒå‡†å¤‡å’Œåˆ›å»ºé¡¹ç›®

- Java(JDK) 1.8
- Flink 1.3.0
- IDEA
- CentOS 7 Or MacOS
- Scala 2.12
- sfl4j 1.7.30

åˆ©ç”¨IDEAåˆ›å»ºJavaçš„Mavené¡¹ç›®FlinkTutorialï¼Œåˆ›å»ºé¡¹ç›®æ—¶çš„ä¸€äº›å‚æ•°å¡«å†™ï¼›

```xml
<name>FlinkTutorial</name>
<groupId>com.rowyet</groupId>
<artifactId>FlinkTutorial</artifactId>
<version>1.0-SNAPSHOT</version>
```

![](../images/2025/03/3e31e135e575947d640a1014f0566428.png "é¡¹ç›®æ ‘ç»“æ„")

è¾“å…¥çš„æ ·ä¾‹æ–‡ä»¶ï¼šé¡¹ç›®ç›®å½•ä¸‹æ–°å»ºæ–‡ä»¶å¤¹inputï¼Œæ–°å»ºä¸€ä¸ª txt æ–‡ä»¶word.txtï¼Œå†…å®¹å¦‚ä¸‹ï¼š

```Markdown
hello world
hello flink
hello java
hello rowyet
```

mavené…ç½®æ–‡ä»¶ï¼špom.xml å†…å®¹å¦‚ä¸‹ï¼š

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.rowyet</groupId>
    <artifactId>FlinkTutorial</artifactId>
    <version>1.0-SNAPSHOT</version>

    <properties>
        <maven.compiler.source>8</maven.compiler.source>
        <maven.compiler.target>8</maven.compiler.target>
        <flink.version>1.13.0</flink.version>
        <java.version>1.8</java.version>
        <scala.banary.version>2.12</scala.banary.version>
        <slf4j.version>1.7.30</slf4j.version>
    </properties>

    <dependencies>
        <!--å¼•å…¥Flinkç›¸å…³çš„ä¾èµ–-->
        <!-- https://mvnrepository.com/artifact/org.apache.flink/flink-java -->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-java</artifactId>
            <version>${flink.version}</version>
        </dependency>

        <!-- https://mvnrepository.com/artifact/org.apache.flink/flink-streaming-java -->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-streaming-java_${scala.banary.version}</artifactId>
            <version>${flink.version}</version>
        </dependency>

        <!-- https://mvnrepository.com/artifact/org.apache.flink/flink-clients -->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-clients_${scala.banary.version}</artifactId>
            <version>${flink.version}</version>
        </dependency>

        <!--å¼•å…¥æ—¥å¿—ç›¸å…³çš„ä¾èµ–-->
        <!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-api -->
        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-api</artifactId>
            <version>${slf4j.version}</version>
        </dependency>

        <!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-log4j12 -->
        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-log4j12</artifactId>
            <version>${slf4j.version}</version>
            <type>pom</type>
            <scope>test</scope>
        </dependency>

        <!-- https://mvnrepository.com/artifact/org.apache.logging.log4j/log4j-to-slf4j -->
        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-log4j12</artifactId>
            <version>${slf4j.version}</version>
        </dependency>
    </dependencies>
</project>
```

log æ—¥å¿—æ ¼å¼ï¼šåœ¨ resources ä¸‹æ–°å»ºæ—¥å¿—æ–‡ä»¶ log4j.propertriesï¼Œå†…å®¹å¦‚ä¸‹ï¼š

```Markdown
### è®¾ç½®###
log4j.rootLogger = error,stdout

### è¾“å‡ºä¿¡æ¯åˆ°æ§åˆ¶æŠ¬ ###
log4j.appender.stdout = org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout = org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern = %-4r [%t] %-5p %c %x -%m%n
```

æœ€åï¼Œåœ¨ src/main/java ä¸‹æ–°å»º Java åŒ… com.rowyet.wcï¼Œå¼€å§‹ç¼–å†™ Flink çš„ç»ƒæ‰‹é¡¹ç›®ï¼›

#### 2ã€DataSet API æ‰¹å¤„ç†å®ç° word count

com.rowyet.wc åŒ…ä¸‹åˆ›å»º Java class æ–‡ä»¶ BatchWorldCountï¼Œå†…å®¹å¦‚ä¸‹ï¼š

```java
package com.rowyet.wc;

import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.api.java.ExecutionEnvironment;
import org.apache.flink.api.java.operators.AggregateOperator;
import org.apache.flink.api.java.operators.DataSource;
import org.apache.flink.api.java.operators.FlatMapOperator;
import org.apache.flink.api.java.operators.UnsortedGrouping;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.util.Collector;

public class BatchWorldCount {
    public static void main(String[] args) throws Exception {
        // 1. åˆ›å»ºæ‰§è¡Œç¯å¢ƒ
        ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();

        // 2. ä»æ–‡ä»¶ä¸­è¯»å–æ•°æ®
        DataSource<String> lineDataSource = env.readTextFile("input/word.txt");

        // 3. å°†æ¯è¡Œæ•°æ®è¿›è¡Œåˆ†è¯ï¼Œè½¬æ¢æˆäºŒå…ƒç»„ç±»å‹ï¼Œåˆ©ç”¨java lambdaè¡¨è¾¾å¼å®ç°flatMap
        FlatMapOperator<String, Tuple2<String, Long>> wordAndOneTuple = lineDataSource.flatMap((String line, Collector<Tuple2<String, Long>> out) ->
        {
            String[] words = line.split(" ");
            for (String word : words) {
                out.collect(Tuple2.of(word, 1L));
            }
        }).returns(Types.TUPLE(Types.STRING, Types.LONG));

        // 4. æŒ‰ç…§wordè¿›è¡Œåˆ†ç»„ï¼Œåˆ©ç”¨wordçš„ç´¢å¼•0ï¼Œå³ç¬¬ä¸€ä¸ªå…ƒç´ è¿›è¡Œåˆ†ç»„
        UnsortedGrouping<Tuple2<String, Long>> wordAndOneGroup = wordAndOneTuple.groupBy(0);

        // 5. åˆ†ç»„å†…è¿›è¡Œèšåˆç»Ÿè®¡ï¼Œæ ¹æ®wordåˆ†ç»„åçš„ç´¢å¼•1ï¼Œå³ç¬¬äºŒä¸ªå…ƒç´ è¿›è¡Œæ±‚å’Œ
        AggregateOperator<Tuple2<String, Long>> sum = wordAndOneGroup.sum(1);

        // 6. æ‰“å°ç»“æœ
        sum.print();
    }
}
```

è¿è¡Œç»“æœï¼š

![](../images/2025/03/2b4d3b6a40f73b2486304220d7382c1c.png "DataSet API æ‰¹å¤„ç†è¿è¡Œç»“æœ")

#### 3. DataSet API VS DataStream API

åœ¨ Flink 1.12 ç‰ˆæœ¬å¼€å§‹ï¼Œå®˜æ–¹å°±æ¨èä½¿ç”¨ DataSteam APIï¼Œåœ¨æäº¤ä»»åŠ¡æ—¶åªéœ€è¦é€šè¿‡ä»¥ä¸‹ shell å‚æ•°æŒ‡å®šæ¨¡å¼ä¸º BATCH å³å¯ï¼›

```bash
bin/flink run -Dexecution.runtime-mode=BATCH BatchWorldCount.jar
```

å¦‚æ­¤ä¸€æ¥ï¼ŒDataSet API å°±å·²ç»å¤„äºè½¯å¼ƒç”¨(soft deprecated)çš„çŠ¶æ€ï¼Œè€Œä¸”å®é™…åº”ç”¨ä¸­åªéœ€è¦ç»´æŠ¤ä¸€å¥— DataStream API å³å¯ï¼ŒçœŸæ­£çš„å‘ **æµæ‰¹ä¸€ä½“** è¿ˆè¿›ã€‚

#### 4. DataStream API æµå¤„ç†å®ç° word count

1ã€æœ‰ç•Œçš„æµå¤„ç†

com.rowyet.wc åŒ…ä¸‹åˆ›å»º Java class æ–‡ä»¶ BoundedStreamWordCountï¼Œå†…å®¹å¦‚ä¸‹ï¼š

```java
package com.rowyet.wc;

import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.datastream.KeyedStream;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.util.Collector;

public class BoundedStreamWordCount {
    public static void main(String[] args) throws Exception {
        // 1. åˆ›å»ºæµå¼çš„æ‰§è¡Œç¯å¢ƒ
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        // 2. è¯»å–æ–‡ä»¶
        DataStreamSource<String> lineDataStreamSource = env.readTextFile("input/word.txt");

        // 3. è½¬åŒ–è®¡ç®—
        SingleOutputStreamOperator<Tuple2<String, Long>> wordAndOneTuple = lineDataStreamSource.flatMap((String line, Collector<Tuple2<String, Long>> out) -> {
                    String[] words = line.split(" ");
                    for (String word : words) {
                        out.collect(Tuple2.of(word, 1L));
                    }
                }
        ).returns(Types.TUPLE(Types.STRING, Types.LONG));

        // 4. åˆ†ç»„
        KeyedStream<Tuple2<String, Long>, String> wordAndOneKeyedStream = wordAndOneTuple.keyBy(data -> data.f0);

        // 5. æ±‚å’Œ
        SingleOutputStreamOperator<Tuple2<String, Long>> sum = wordAndOneKeyedStream.sum(1);

        // 6. æ‰“å°
        sum.print();

        // 7. å¯åŠ¨æ‰§è¡Œ
        env.execute();


    }
}
```

![](../images/2025/03/aeb3282325ef3690663674b1fc5d5740.png "æœ‰ç•Œæµå¤„ç†è¿è¡Œç»“æœ")

å‘ç°è·Ÿä¹‹å‰çš„è¿è¡Œç»“æœæœ‰äº›ä¸ä¸€æ ·ï¼Œå…·ä½“åŒºåˆ«åœ¨å“ªå‘¢ï¼Ÿ

- æ•°æ®å‡ºç°æ— åºäº†ï¼Œè€Œä¸”æ˜¯æ¥ä¸€æ¡å¤„ç†ä¸€æ¡ï¼Œæœ€ç»ˆçš„ç»“æœæ‰æ˜¯å‡†ç¡®çš„ç»“æœï¼›
- ç»“æœå‰é¢æœ‰ä¸€ä¸ªåºå·ï¼Œè€Œä¸”ç›¸åŒçš„ word åºå·ç›¸åŒï¼Œè¿™æ˜¯å› ä¸ºFlinkæœ€ç»ˆè¿è¡Œåœ¨åˆ†å¸ƒå¼çš„é›†ç¾¤å†…ï¼Œè€Œè¿™ä¸ªåºå·æ˜¯ IDEA æ¨¡æ‹Ÿåˆ†å¸ƒå¼é›†ç¾¤ï¼Œä»£è¡¨ä½ çš„ CPU çš„æ ¸æ•°çš„ä¸€ä¸ª CPU åºå·ï¼Œåšä¸»çš„ CPU æ˜¯ 8 æ ¸çš„ï¼ˆå¯ä»¥ç†è§£ä¸ºæœ‰ CPU8 ä¸ªï¼‰ï¼Œæ‰€ä»¥åºå·ä¸ä¼šå¤§äº 8ï¼Œä»¥æ­¤ç±»æ¨è‡ªå·±çš„ CPU æ€»æ ¸æ•°å’Œè¿è¡Œç»“æœï¼Œè‡³äºä¸ºä»€ä¹ˆç›¸åŒçš„ word åºå·æ˜¯ä¸€æ ·çš„ï¼Œæ˜¯å› ä¸ºç›¸åŒçš„ word ä½œä¸ºåˆ†åŒºçš„ keyï¼Œæœ€ç»ˆè‚¯å®šè¦åœ¨åŒä¸€ä¸ªå¤„ç†å™¨ä¸Šæ‰å¯ä»¥è¿›è¡Œåç»­çš„ sum ç»Ÿè®¡å‘¢ã€‚

2ã€æ— ç•Œçš„æµå¤„ç†

è¿™é‡Œåˆ©ç”¨ linux çš„ netcat å‘½ä»¤ç›‘å¬ç«¯å£ 7777 çš„è¿ç»­ä¸æ–­è¾“å…¥çš„ word ä¸ºä¾‹ï¼Œå®ç°æ— ç•Œçš„æµå¤„ç† word count çš„ç»Ÿè®¡ï¼›

com.rowyet.wc åŒ…ä¸‹åˆ›å»º Java class æ–‡ä»¶ StreamWordCountï¼Œå†…å®¹å¦‚ä¸‹ï¼š

```Java
package com.rowyet.wc;

import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.api.java.utils.ParameterTool;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.datastream.KeyedStream;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.util.Collector;


public class StreamWordCount {
    public static void main(String[] args) throws Exception {
        // 1. åˆ›å»ºæµå¼ç¯å¢ƒ
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        // 2. è¯»å–æ–‡æœ¬æµ
       // DataStreamSource<String> lineDataSource = env.socketTextStream("127.0.0.1", 7777);  //æµ‹è¯•å¯ä»¥å†™æ­»å‚æ•°

        //ç”Ÿäº§ä¸­ä¸€èˆ¬ï¼Œé€šè¿‡mainå‡½æ•°åæ¥å‚æ•°å®ç°
        ParameterTool parameterTool = ParameterTool.fromArgs(args);
        String host = parameterTool.get("host");
        int port = parameterTool.getInt("port");

        // è¿è¡Œæ—¶åœ¨èœå•æ Runâ€”>Edit Configurationâ€”>Program argumentsæ–‡æœ¬æ¡†å†…å¡«å…¥  --host "127.0.0.1" --port 7777
        DataStreamSource<String> lineDataSource = env.socketTextStream(host, port);


        // 3. è½¬æ¢å¤„ç†
        SingleOutputStreamOperator<Tuple2<String, Long>> wordOneTuple = lineDataSource.flatMap((String line, Collector<Tuple2<String, Long>> out) ->
                {
                    String[] words = line.split(" ");
                    for (String word : words) {
                        out.collect(Tuple2.of(word, 1L));
                    }
                }
        ).returns(Types.TUPLE(Types.STRING, Types.LONG));

        // 4. åˆ†ç»„
        KeyedStream<Tuple2<String, Long>, String> wordAndOneKeyedStream = wordOneTuple.keyBy(data -> data.f0);

        // 5. æ±‚å’Œ
        SingleOutputStreamOperator<Tuple2<String, Long>> sum = wordAndOneKeyedStream.sum(1);

        // 6. è¾“å‡º
        sum.print();

        // 7. å¯åŠ¨æ‰§è¡Œ
        env.execute();

    }
}
```

è¿è¡Œï¼š

1. åœ¨æŸä¸€å° Linux æˆ–è€… MacOS å¼€å¯netcatå‘½ä»¤ç›‘å¬æœ¬åœ°7777ç«¯å£ï¼Œåšä¸»çš„æ˜¯æœ¬åœ°çš„ MacOS ç»ˆç«¯, æŒ‡ä»¤æ˜¯:

```bash
nc -lk 7777
# å›è½¦å¯åŠ¨ï¼Œå…ˆä¸è¦è¾“å…¥å†…å®¹
```

2. å¯åŠ¨åˆšåˆšå†™å¥½çš„ Java Class æ–‡ä»¶ StreamWordCount, æš‚æ—¶çœ‹ä¸åˆ°ä»»ä½•ä¸œè¥¿ï¼Œä¸€ç›´ç­‰å¾…è¾“å‡ºçš„ç©ºç™½è¾“å‡ºæ¡†

![](../images/2025/03/db0256c11f8e0015e2a9fac9e07fac3f.png "æ— ç•Œæµå¤„ç†ç­‰å¾…ç»“æœ")


3. åœ¨æ­¥éª¤ 1 çš„ MacOS ç»ˆç«¯å¯åŠ¨çš„netcatç¯å¢ƒå†…è¾“å…¥ä¸€äº›èŠå¤©æ¶ˆæ¯

![](../images/2025/03/2d8e80f675fb6784769988a9595f2ed8.png "æ— ç•Œæµå¤„ç†ç­‰å¾…ç»“æœ")

4. æœ€ä¸­åœ¨ IDEA çš„è¿è¡Œç»“æœå†…ä¼šå®æ—¶å¾—åˆ°è¿ç®—ç»“æœ

![](../images/2025/03/29917e53f03a71098ab629e4d77eb2b9.png "æ— ç•Œæµè®¡ç®—å¾—åˆ° word count")

## tip [ğŸ”](#weekly-106)

## share [ğŸ”](#weekly-106)

[readme](../README.md) | [previous](202503W2.md) | [next](202503W4.md)
